{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NJNMF sample program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jwnmf\n",
    "import njnmf\n",
    "import njnmf_PU\n",
    "import build_graph\n",
    "import time\n",
    "import evaluate\n",
    "import init_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose data you would like to use\n",
    "### data statics are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cite\n",
      "number of nodes : 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7363f3cdbca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# data = \"cora\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_ori\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_clus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/maekawaseiji/Google Drive/study/njnmf/NJNMF-master/build_graph.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"cite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS_ori\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfor_cites_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS_ori\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_ori\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maekawaseiji/Google Drive/study/njnmf/NJNMF-master/build_graph.py\u001b[0m in \u001b[0;36mfor_cites_contents\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mclus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"number of nodes : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"number of attributes : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;31m# print (clus)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m############ download edges #################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data=\"WebKB_univ\"\n",
    "# data=\"citeseer\"\n",
    "# data = \"polblog\"\n",
    "# data = \"cora\"\n",
    "data_path = \"data/\"+data\n",
    "S, S_ori, A, true_clus, flag, A_ori = build_graph.build_graph(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_kmeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters and Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing_time:0.3993818759918213[sec]\n"
     ]
    }
   ],
   "source": [
    "k1=4 # number of clusters you want to extract\n",
    "k2=4 # number of topic2 \n",
    "lam=0.001 # balancing parameter between the topology and attributes\n",
    "iteration=100 # number of iterations\n",
    "init=1 # 0: random initialization, 1: kmeans initialization\n",
    "start = time.time() #memo start time\n",
    "V = njnmf.graph_operation(k1,k2,lam,S,A,iteration,init,data,\"\",0)\n",
    "elapsed_time = time.time() - start  #measure elapsed time\n",
    "print ((\"optimizing_time:{0}\".format(elapsed_time)) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you would like to use PU version, please use the cell below\n",
    "### If not, go to the next cell without implemeting this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing_time:2.119202136993408[sec]\n"
     ]
    }
   ],
   "source": [
    "k1=4 # number of clusters you want to extract\n",
    "k2=20 # number of topic2 \n",
    "lam=0.0001 # balancing parameter between the topology and attributes\n",
    "iteration=100 # number of iterations\n",
    "init=1 # 0: random initialization, 1: kmeans initialization\n",
    "rho = 0.1 # missing values ratio in the adjacency matrix (It is hard to detect the correct value.)\n",
    "start = time.time() #memo start time\n",
    "V = njnmf_PU.graph_operation(k1,k2,lam,S,A,iteration,init,data,\"\",0,rho,S_ori)\n",
    "elapsed_time = time.time() - start  #measure elapsed time\n",
    "print ((\"optimizing_time:{0}\".format(elapsed_time)) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering results are evaluated with (modularity, entropy and ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modularity: 0.7377830006088405\n",
      "entropy: 0.15230280029483292\n",
      "ARI: 0.9939919466847695\n"
     ]
    }
   ],
   "source": [
    "k = k1\n",
    "clus=[]\n",
    "for i in range(V.shape[1]):\n",
    "    clus.append([])\n",
    "pred = V.argmax(1)\n",
    "for i in range(V.shape[0]):\n",
    "    clus[pred[i]].append(i)\n",
    "print(\"modularity: \" + str(evaluate.cal_modularity(clus,S,k)))\n",
    "print(\"entropy: \" + str(evaluate.cal_entropy(clus,A,k)))\n",
    "if true_clus != []:\n",
    "    # print(\"NMI: \" + str(evaluate.cal_nmi(true_clus,clus)))\n",
    "    print(\"ARI: \" + str(evaluate.ARI(true_clus,pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
